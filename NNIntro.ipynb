{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "dESFyqNXn1cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузка тренировчного и тестового наборов данных.\n",
        "#Для загрузки используется библиотека фраемворка pytorch\n",
        "#под названием torchvision. В данном случае мы загружаем\n",
        "#черно белые изображения одежды из 10 категорий. Подробнее:\n",
        "#https://github.com/zalandoresearch/fashion-mnist\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "lHVaEuSCn1On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Этот класс копирует поведение встроенного класса Dataset \n",
        "#библиотеки pytorch. В данном случае data - имитация какого-то\n",
        "#набора данных. Волшебные методы __len__ и __getitem__ позволяют\n",
        "#расширить функционал класса python, делая итеарацию по набору\n",
        "#данных проще и удобнее.\n",
        "class test:\n",
        "  def __init__(self, data):\n",
        "      self.data = data\n",
        "  \n",
        "  def __len__(self,):\n",
        "      #вызывается в момент len(экземпляр класса test)\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, key):\n",
        "  #   #вызывается в момент экземпляр класса test [index]\n",
        "      return self.data[key]\n",
        "\n",
        "a = [1,2,3,4,5]\n",
        "check = test(a)\n",
        "check[2]"
      ],
      "metadata": {
        "id": "rrh2plDPn1G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "qezC39tRn1EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#каждый элемент данных, содержащийся training_data (аналогично для test_data)\n",
        "#представляет из себя кортеж (tuple). Перывый элемент кортежа - изображение, \n",
        "#второй - метка класса. Далее мы нарисуем изображение, чтобы убедиться, что \n",
        "#метка класса и изображение совпадают.\n",
        "image, label = test_data[5]\n",
        "label"
      ],
      "metadata": {
        "id": "Q6Loee_atSWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 - соответсует метке брюк\n",
        "image = ToPILImage(mode='L')(image)\n",
        "plt.imshow(image, cmap = 'gray')"
      ],
      "metadata": {
        "id": "89F7Y2IrvV4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size - размер пакета, показывает какого количество данных за раз будет\n",
        "#подаваться нейронной сети на вход. Если batch_size = 64, то за раз нейросеть\n",
        "#будет получать 64 изображения. Этот параметр задается в самом начале и не меняется\n",
        "#на всем этапе обучения. Является гиперпараметром. Влияет на точность.\n",
        "batch_size = 64\n",
        "\n",
        "#Создание экземпляра класса DataLoader, который будет автоматически собирать \n",
        "#данные в пакет нужного нам размера. По сути расширение Dataset. Далее мы будем\n",
        "#использовать именно DataLoader. Можно посмотреть какого размера данные (тензоры)\n",
        "#на выходе DataLoader.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "4k_HFWJlwdWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#выбор устройства для обучения. Чтобы поменять на gpu (видеокарту) для увеличения\n",
        "#скорости нужно перейти в кладку \"Среда выполнения\" (сверху) и выбрать параметр\n",
        "#\"сменить среду выполнения\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Создание класса нейронной сети. Он наследуется от nn.Module (класс Pytorch)\n",
        "#В этом классе вам нужно определять слои нейронной сети. Метод forward - исполь\n",
        "#зуется для прямого прохода сети (смотри презентацию), т.е. считает предсказание.\n",
        "\n",
        "#nn.Sequential используется для объединения нескольких блоков нейронной сети в один\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "    #предсказание\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model_fc = NeuralNetwork().to(device)\n",
        "print(model_fc)"
      ],
      "metadata": {
        "id": "oZJNXt_1xhKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверка, что нейронная сеть работает\n",
        "for X, y in test_dataloader:\n",
        "    X = X.to(device)\n",
        "    y_pred = model_fc(X)\n",
        "    print(y_pred.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "i9wkLkaRyn_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#выбор функции потерь, которой мы будем считать ошибку предсказания. Для клас-\n",
        "#сификации обычно используется CrossEntropyLoss, но можно использовать и MSE.\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Выбор оптимайзера. Он занимается обновлением параметров. Сейчас не вижу смысла\n",
        "#дотошно разбирать как он работает. Он, в отличии от нас на лекции, более хитро\n",
        "#обновляет веса модели, а раз он обновляет веса именно ему нужно передать параметр\n",
        "#скорости обучения lr!\n",
        "optimizer = torch.optim.Adam(model_fc.parameters(), lr=2e-3)"
      ],
      "metadata": {
        "id": "wzKOSkiCzBO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    #перевод модели в режим тренировки. Это нужно указывать, так как некоторые\n",
        "    #слои сети по-разному считаются на тренировке и на тесте.\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        #извлекаем данные из dataloader и ФИЗИЧЕСКИ перекладываем их на то же\n",
        "        #устройство, на котором находится модель. \n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        #делаем предсказание\n",
        "        pred = model(X)\n",
        "        #считаем ошибку\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        #зануляем градиенты с предыдущего шага\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #считаем градиенты\n",
        "        loss.backward()\n",
        "        #обновляем веса модели\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    #для предсказания на тестовых данных всегда используейте with torch.no_grad()\n",
        "    #чтобы pytorch не считал градиенты.\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "6icKcsQqzG5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#собираем все вместе. Каждая эпоха состоит из 2х циклов - обучения и теста. \n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model_fc, loss_fn, optimizer)\n",
        "    test(test_dataloader, model_fc, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "S8Zo3Iurzpv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_data[5]\n",
        "y = model_fc(img)"
      ],
      "metadata": {
        "id": "8ITOAlc939C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_fc.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "lTwFKKMXsR7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Для визуализации результатов\n",
        "def plot(model, testdataset, imgs = 9):\n",
        "  fig = plt.figure(figsize=(16,16))\n",
        "  for i in range(imgs):\n",
        "      a = fig.add_subplot(3, 3, i + 1)\n",
        "      image, label = testdataset[i]\n",
        "      predict = torch.argmax(model(image))\n",
        "      image = ToPILImage(mode='L')(image)\n",
        "      plt.imshow(image, cmap = 'gray')\n",
        "      a.set_title(str(predict == label))\n",
        "  plt.show()\n",
        "plot(model_fc, test_data)"
      ],
      "metadata": {
        "id": "KLWIatt52jI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрики ###"
      ],
      "metadata": {
        "id": "9EVGq_ERrKjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "cwUQaTFifKEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = []\n",
        "real_labels = []\n",
        "model_fc.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X = X.to(device)\n",
        "        pred = model_fc(X)\n",
        "        predicts.extend(pred.argmax(1).tolist())\n",
        "        real_labels.extend(y.tolist())"
      ],
      "metadata": {
        "id": "avavwHtVgipr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicts[:5], real_labels[:5]"
      ],
      "metadata": {
        "id": "XW4AigZFhFuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(predicts, real_labels, average=None)"
      ],
      "metadata": {
        "id": "nzHwrR1KhkwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(predicts, real_labels, average=None)"
      ],
      "metadata": {
        "id": "Z0aWEme-hoo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(predicts, real_labels, labels=range(10))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "SKuB7LOz754E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ConvNeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layer1 = self.create_block(1, 16, 3)\n",
        "        self.layer2 = self.create_block(16, 32, 3)\n",
        "        self.layer3 = self.create_block(32, 64, 3)\n",
        "        self.classificator = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "    def create_block(self, in_channels, out_channels, kernel_size):\n",
        "        layer = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size),\n",
        "                              nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "                              nn.ReLU())\n",
        "        return layer\n",
        "    #предсказание\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classificator(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "conv_model = ConvNeuralNetwork().to(device)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    X = X.to(device)\n",
        "    y_pred = conv_model(X)\n",
        "    print(y_pred.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "P-mvrHo2hyng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#выбор функции потерь, которой мы будем считать ошибку предсказания. Для клас-\n",
        "#сификации обычно используется CrossEntropyLoss, но можно использовать и MSE.\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Выбор оптимайзера. Он занимается обновлением параметров. Сейчас не вижу смысла\n",
        "#дотошно разбирать как он работает. Он, в отличии от нас на лекции, более хитро\n",
        "#обновляет веса модели, а раз он обновляет веса именно ему нужно передать параметр\n",
        "#скорости обучения lr!\n",
        "optimizer = torch.optim.Adam(conv_model.parameters(), lr=2e-3)\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, conv_model, loss_fn, optimizer)\n",
        "    test(test_dataloader, conv_model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "DHMrpcnpej3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, _ = test_data[5]"
      ],
      "metadata": {
        "id": "fV138_bwhp-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_ = ToPILImage(mode='L')(image)\n",
        "plt.imshow(image_, cmap = 'gray')"
      ],
      "metadata": {
        "id": "s37jkd8imOpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one = image[:,:,10:21]"
      ],
      "metadata": {
        "id": "TI2AYfyIk7-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_ = ToPILImage(mode='L')(one)\n",
        "plt.imshow(image_, cmap = 'gray')"
      ],
      "metadata": {
        "id": "M9Gnm-1-k-Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "background = torch.zeros(1, 28, 28)\n",
        "background[:,:, 4:15] = one\n",
        "image_ = ToPILImage(mode='L')(background)\n",
        "plt.imshow(image_, cmap = 'gray')"
      ],
      "metadata": {
        "id": "Homo2iZ7ldBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузить сохраненную модель\n",
        "weights = torch.load('your_model.pt',  map_location=torch.device('cpu'))\n",
        "fc = NeuralNetwork()\n",
        "fc.load_state_dict(weights)"
      ],
      "metadata": {
        "id": "lTYLVkUYm170"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# подайте батч модели, чтобы получить предсказания.\n",
        "# Сравните ответы!\n",
        "batch = torch.stack([image,background], 0)"
      ],
      "metadata": {
        "id": "551BCc0no1N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание ###\n",
        "**Вам нужно улучшить качество сверточной нейронной сети. Качество будем смотреть по Confusion Matrix (смотри раздел с метриками). Сохраните веса модели (файл <your_model_name.pt>)!**\n",
        "___\n",
        "> Как можно улучшить качество?\n",
        "\n",
        "1.   Добавить слой BatchNorm2d (слой нормализации добавляют перед функцией активации)\n",
        "2.   Сделать модель глубже\n",
        "3.   Сделать слой классификатора более глубоким.\n",
        "\n",
        "Это творческое задание, не бойтесь пробовать !\n",
        "\n"
      ],
      "metadata": {
        "id": "-_pgdN7IoDqw"
      }
    }
  ]
}